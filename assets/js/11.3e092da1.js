(window.webpackJsonp=window.webpackJsonp||[]).push([[11],{199:function(e,a,s){"use strict";s.r(a);var t=s(3),i=Object(t.a)({},(function(){var e=this,a=e.$createElement,s=e._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[s("h1",{attrs:{id:"architecture"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#architecture"}},[e._v("#")]),e._v(" Architecture")]),e._v(" "),s("h2",{attrs:{id:"sharding-with-kafka-message-offset-stripe-default"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#sharding-with-kafka-message-offset-stripe-default"}},[e._v("#")]),e._v(" Sharding with kafka message offset stripe (default)")]),e._v(" "),s("p",[e._v("clickhouse_sinker guarantee:")]),e._v(" "),s("ul",[s("li",[e._v("at-least-once")]),e._v(" "),s("li",[e._v("Duplicated messages (per topic-partition-offset) are routed to the same ClickHouse shard.")])]),e._v(" "),s("p",[e._v("So if you setup ClickHouse properly(ReplacingMergeTree ORDER BY (__kafak_topic, __kafka_partition, __kafka_offset)), you could get exactly-once semantic.")]),e._v(" "),s("p",[e._v("It's hard for clickhouse_sinker to guarantee exactly-once semantic without ReplacingMergeTree. Kafka consumer group load-balance cause duplicated messages if one consumer quit suddenly.")]),e._v(" "),s("p",[e._v("The flow is:")]),e._v(" "),s("ul",[s("li",[e._v("Fetch message via kafka-go or samara, which starts internally an goroutine for each partition.")]),e._v(" "),s("li",[e._v("Parse messages in a global goroutine pool(pool size is customizable), fill the result to a ring according to the message's partition and offset.")]),e._v(" "),s("li",[e._v("Generate a batch if messages in a ring reach a batchSize bondary, or flush timer fire. This ensures offset/batchSize be same for all messages inside a batch.")]),e._v(" "),s("li",[e._v("Write batchs to ClickHouse in a global goroutine pool(pool size is fixed according to number of task and clickhouse shards). Batch is routed according to "),s("code",[e._v("(kafka_offset/roundup(batch_size))%clickhouse_shards")]),e._v(".")])]),e._v(" "),s("h2",{attrs:{id:"sharding-with-custom-key-and-policy"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#sharding-with-custom-key-and-policy"}},[e._v("#")]),e._v(" Sharding with custom key and policy")]),e._v(" "),s("p",[e._v("clickhouse_sinker guarantee:")]),e._v(" "),s("ul",[s("li",[e._v("at-least-once")]),e._v(" "),s("li",[e._v("Every message is routed to the determined (per "),s("code",[e._v("shardingKey")]),e._v(" and "),s("code",[e._v("shardingPolicy")]),e._v(") ClickHouse shard.")])]),e._v(" "),s("p",[s("code",[e._v("shardingKey")]),e._v(" value is a column name. "),s("code",[e._v("shardingPolicy")]),e._v(" value is "),s("code",[e._v("stripe,<size>")]),e._v(" or "),s("code",[e._v("hash")]),e._v(".\nThe hash function used internally is xxHash64.")]),e._v(" "),s("p",[e._v("The flow is:")]),e._v(" "),s("ul",[s("li",[e._v("Fetch message via kafka-go or samara, which starts internally an goroutine for each partition.")]),e._v(" "),s("li",[e._v("Parse messages in a global goroutine pool(pool size is customizable), fill the result to a ring according to the message's partition and offset.")]),e._v(" "),s("li",[e._v("Shard messages in a ring if reach a batchSize bondary, or flush timer fire. There's one-to-one relationship between shard slots and ClickHouse shards.")]),e._v(" "),s("li",[e._v("Generate batches for all shard slots if messages in one shard slot reach batchSize, or flush timer fire. Those batches form a "),s("code",[e._v("BatchGroup")]),e._v(". The "),s("code",[e._v("before")]),e._v(" relationship could be impossilbe if messages of a partition are distributed to multiple batches. So those batches need to be committed after ALL of them have been written to clickhouse.")]),e._v(" "),s("li",[e._v("Write batchs to ClickHouse in a global goroutine pool(pool size is fixed according to number of task and clickhouse shards).")])])])}),[],!1,null,null,null);a.default=i.exports}}]);